---
layout: post
title: "Worley Noise"
date: 2022-05-15 11:53:00 -0000
categories: Blog posts
---

Anders Blomqvist andblomq@kth.se 
David Ã…sberg dasberg@kth.se 

# Generating Noise
Last blog post we showed off a volumetric ray-marcher that could actually render a volume of noise. 

But what kind of noise should you use for clouds? And how do you generate that noise?

## Worley Noise

A great way of making realistic looking clouds is using something called Worley Noise. Worley noise is genereated by scattering a number of points, and then for each pixel on the noise texture, we will find the closest point in the set of points. Then, we will use the distance between the point and the pixel to determine the color of the pixel. Pixels that are closer to the point will get a more white color value, and pixels that are further away will get a more black color value.

![Figure 1. 2D Worley Noise](https://www.shadertoy.com/media/shaders/MstGRl.jpg)

You can see that the texture has some cloud-looking features.

This idea can then also be extended to a 3D noise texture. In this case, you simply scatter a bunch of points in 3d space, and then for each pixel (in 3D space) you calculate the closest point in the set of points. Then, you use the distance between the point and the pixel to determine the color of the pixel. 

To improve the detail of the clouds and make them look more realistic, we can generate a different noise texture in each of the RGBA-channels of the texture, and then sample a weighted average of them when rendering the clouds. 

We can also make another lower resolution texture, that is used to even further improve the details of the clouds. This lower resolution texture is then used to "eat away" or subtract the edges of the cloud to achieve some detail in the clouds. This texture will be refered to as "detail noise" in later blog posts.

To generate this noise fast enough, it is best to use Compute Shaders that run on the GPU. A large texture of 128x128x128 will contain 2,097,152 3D-pixels. And for each of these pixels we will have to iterate over all the scattered points to find the closest one. This is a lot of work, but can be done in parallel on the GPU to speed up the process. Another optimization is to divide the texture into a number of cells, and then only place a point in each of the cells, this will guarantee that when we are looking for the closest point, it will be in the same cell as the pixel we are looking at, or one of the 26 neighboring cells.

We can create a list of offsets that we can use as a lookup table when looking for the closest point. This will make the process much faster. The image below shows all the cube offsets we need. 

![Figure 2. Lookup table for the closest point in the set of points](/dgi22_project/assets/Cubeindices.png)


Now when we ray march this texture, we get a cloud-like image.
![Figure 3. Ray marching Worley Noise](/dgi22_project/assets/something_that_looks_like_clouds.png)


All the code for generating the noise, and the idea of how to use it was all possible because of Sebastian Lague and his [video on procedural generation of clouds](https://youtu.be/4QOcCGI6xOU). Without his video, we would probably still be scratching our heads on how to make a compute shader run. 

In the next post, we will combine the ray marching, the light marching and the noise generation to make a cloud.